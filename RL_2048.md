[Home]({{ site.baseurl }}{% link index.md %})

[Reinforcement Learning - 2048]({{ site.baseurl }}{% link RL_2048.md %})

* * *

# Renforcement Learning - 2048

Reinforcement learning to solve the 2048 game. The project begins with an implementation of a neural network. At first the inputs are the 4 x 4 grid of the game, and the outputs are given by the set of possible actions (there are four possible actions at each state of the game, up, down, right, left).
Two algorithms will be used to solve the neural network structures : 
- Basic **Genetic Algorithm**
- **NEAT Algorithm** (Neuroevolution of Augmenting Topologies), which fits better the context of genetic evolution applied to neural networks.

The last approach is **Q-Learning**.

## The Game

2048 is played on a gray 4Ã—4 grid, with numbered tiles that slide smoothly when a player moves them using the four arrow keys. Every turn, a new tile will randomly appear in an empty spot on the board with a value of either 2 or 4. (source [wikipedia](https://en.wikipedia.org/wiki/2048_(video_game)))
Part of the challenge of this project for me was to code the game from scratch, with a working pygame interface. 

## Genetic Algorithm

The idea here is simple. We'll be using a simple feed forward NN to decide which action, either up, down, right or left. A grid is of dimension 4 x 4, so the neural network will take as input a vector of dimension 16 corresponding to the grid. The output layer will correspond to the decision to take given the current state of the grid, so it will be a 4-dimensions vector.
The first step is to choose the neural network structure. One can choose to directly connect the input layer to the output, or to work with a deep neural network with several hidden layers in-between.

## Neat Algorithm

## Q-Learning