[Home]({{ site.baseurl }}{% link index.md %})

[Reinforcement Learning - 2048]({{ site.baseurl }}{% link RL_2048.md %})

* * *

# Renforcement Learning - 2048

<p style="text-align: justify;">
Reinforcement learning to solve the 2048 game. The project begins with an implementation of a neural network. At first the inputs are the 4 x 4 grid of the game, and the outputs are given by the set of possible actions (there are four possible actions at each state of the game, up, down, right, left).
Two algorithms will be used to solve the neural network structures : 
</p>

- Basic **Genetic Algorithm**
- **NEAT Algorithm** (Neuroevolution of Augmenting Topologies), which fits better the context of genetic evolution applied to neural networks.

The last approach is **Q-Learning**.

## The Game

<p style="text-align: justify;">
2048 is played on a gray 4 Ã— 4 grid, with numbered tiles that slide smoothly when a player moves them using the four arrow keys. Every turn, a new tile will randomly appear in an empty spot on the board with a value of either 2 or 4. (source: <a href="https://en.wikipedia.org/wiki/2048_(video_game)">wikipedia</a>)
Part of the challenge of this project for me was to code the game from scratch, with a working pygame interface. 
</p>

## Genetic Algorithm

<p style="text-align: justify;">
The idea here is simple. We'll be using a simple feed forward NN to decide which action to perform, either up, down, right or left. A grid is of dimension 4 x 4, so the neural network will take as input a vector of dimension 16 corresponding to the grid. The output layer will correspond to the decision to take given the current state of the grid, so it will be a 4-dimensions vector.
</p>

<p style="text-align: justify;">
The first step is to choose the neural network structure. One can choose to connect directly the input layer to the output, or to work with a deep neural network with several hidden layers in-between.
</p>

<p style="text-align: justify;">
The genetic algorithm consists of initialize our first generation of n individuals, then evaluate each individual with a fitness function to select the best ones and breed the next generation with them. However, you can modify a little bit the rules by either selecting some lucky ones to contribute for the next generation, or you can also choose to unselect some unlucky ones from the best performers. Once the selection done, comes the breeding step. The idea is pretty much straight forward, you generally take 2 parents (the number can varry) to breed 2 children(again, this number can varry). The breeding consists of genetic operations, in this project I will only perform crossover and mutation operations. Crossover is roughly mixing the genome of the parents, and mutation is defining a probability of random changes for each gene. Breeding is done when the next generation is composed of n individuals. The concept of the genetic algorithm lies in repeating this steps until you reach a decent value for your fitness function.
</p>

<p style="text-align: justify;">
How do we define our population ? Well, since a feed forward neural network with known structure can be defined only with his set of weights, our population can be n differents sets of weights, all with the same dimension because we're using a predetermined NN structure. Crossover operator corresponds to uniformly choose for each weight between parent A or parent B. And finally mutation assigns a probability p for each weight to be choosen randomly. For the initialisation step, every weights are choosen randomly (following the same distribution or not).
</p>

## Neat Algorithm

## Q-Learning